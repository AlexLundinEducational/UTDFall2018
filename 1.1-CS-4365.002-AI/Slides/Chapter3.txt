Chapter 3 (page 77)
Solving by searching
non deterministic - program yeilds different results on different runs

3.1 Problem solving agents
	Goal - set of world states
	actions - cause transitions of world states
	Process
		1 goal formulation
			determines the stopping point for searching
		2 problem formulation
			determines what actions and states to condiser
		3 search
			looks for sequence of actions that results in 
			transition from intial state to goal
		4 execution
			follow sequence to goal
			
3.2 Formulating problems
	Knowledge amounts:
		Single state
			agents knows all effects of it's actions
			agent has all knowledge of world
				*simplest, search results in solution
		Multi state
			agents knows all effects of it's actions
			agent has some knowledge of world
				*plan ahead
		Contigency
			agents actions are non deterministic
			agent is missing some knowledge of world
				*scan during execution
				*agent can act before search returns solution
		Exploration
			agent is completely unware of results of its actions
			agent is missing all knowledge of world
3.3 Example problems

	problem - collection of information that the agent will
		use to decide what to do
		information:
			1 initial state - the starting space that the agent knows
				iteself to be in
				
			2 operator set - collection of actions, which transitions the agent to a state

			3 goal test - determines if solution is reached
			4 path cost - prioritizes solutions
			
	state space - all reachable states
	path - route from initial to solution
	
	Multistate probs:
		initial state SET
		operator set - action might reach a SET of states, rather than just one
		path - connects a SET of states
		solution - a path that leads to a SET of goal states
		
	Measuring
		1 solution or no?
		2 path cost
		3 search cost
		4 total cost
	Examples
		8 puzzle
			states - specifies each locations of the eight tiles as well as the blank
			operators - blank moves left, right, up or down
			goal test - state matches goal configuration shown
			path cost - each step is 1
			
		8 queens
			states - arrangement of 0 to 8 queens
			operators - add queen to any square
			goal test - all 8 queens on board, not attacking any other queen
			path cost - 0, goal configuration is all that matters
		Vaccum
			Single State
				states - one of eight states
				operators - suck, move right, move left
				goal test - all dirt is sucked
				path cost - 1
			Multi State
				state set - subset of states 1-8
				operators - suck, move right, move left
				goal test - all states in set have no dirt
				path cost - 1
3.4 Searching for solutions 92


3.5 Search strategies 95
	uninformed - no information about number of steps to goal
		also called blind
		distinguished by order of node expansion
		1 Bread first
		2 Uniform cost
		3 Depth first
		4 Depth limited
		5 iterative deepening
		6 bidirectional
	informed - 
		heuristic

3.6 Avoiding repeated states
	do not return the state you came from
		have expand function refuse to generate any successor that is the same state 
		as the parent
	do not create paths with cycles
		have expand function refuse to
		generate any sucessor of a node 
		that is the same as any of the nodes ancestors
	do not generate any state that was generated before
		keep all states in memory
3.7 Constraint Satisfaction Search

3.8 Summary (107)
	Why is searching valueable?
		Because it gives a solution when the agent is not clear
		on which immediate action is best. The search returns
		a possible sequence of actions for the agent to 
		consider.
	
	Definitions:
		problem
			1 intial state 
			2 set of operators
			3 goal test function
			4 path cost function
			
		environment - represents the problem state space
		path - route through state space, from initial state to solution
		breadth first - expands shallowest node first
		uniform cost - expands least cost node first
		depth first - expands deepest node first
		depth limited - place limit on how deep a depth first search can go
		iterative deepening - depth-limited with increasing limt until goal is reached
		bidirectional - reduces time complexity, increases memory useage
		
	Evaluation:
		completeness
		optimality
		time complexity
		space complexity
		
Exercises (109)